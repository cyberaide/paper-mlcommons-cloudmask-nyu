@misc{las-2023-cloudmask-related,
  author =	 {von Laszewski, Gregor and Gu, Ruochen},
  title =	 {An Overview of MLCommons Cloud Mask Benchmark: Related Research and Data},
  howpublished = {submitted to ArXiv, },
  url = {https://github.com/laszewski/papers/raw/master/vonLaszewski-cloudmask-related.pdf},
  note={\url{https://arxiv.org/submit/5278659/view}},
  month =	 may,
  year =	 2020
}

@misc{jackson-2020-eu,
  author =	 {Jackson, S. and Thiyagalingam, J. and Cox, C.},
  title =	 {A Machine Learning Approach to Cloud Masking in
                  Sentinel-3 SLSTR Data},
  howpublished = {EGU General Assembly 2020, Poster},
  url =		 {https://doi.org/10.5194/egusphere-egu2020-21593},
  month =	 may,
  year =	 2020
}


@Article{amt-15-7195-2022,
  AUTHOR =	 {Petracca, I. and De Santis, D. and Picchiani, M. and
                  Corradini, S. and Guerrieri, L. and Prata, F. and
                  Merucci, L. and Stelitano, D. and Del Frate, F. and
                  Salvucci, G. and Schiavon, G.},
  TITLE =	 {Volcanic cloud detection using Sentinel-3 satellite
                  data by means of neural networks: the Raikoke 2019
                  eruption test case},
  JOURNAL =	 {Atmospheric Measurement Techniques},
  VOLUME =	 15,
  YEAR =	 2022,
  NUMBER =	 24,
  PAGES =	 {7195--7210},
  URL =		 {https://amt.copernicus.org/articles/15/7195/2022/},
  DOI =		 {10.5194/amt-15-7195-2022}
}

@INPROCEEDINGS{picchiani2018,
  author =	 {Picchiani, Matteo and Del Frate, Fabio and Sist,
                  Massimiliano},
  booktitle =	 {IGARSS 2018 - 2018 IEEE International Geoscience and
                  Remote Sensing Symposium},
  title =	 {A Neural Network Sea-Ice Cloud Classification
                  Algorithm for Copernicus Sentinel-3 Sea and Land
                  Surface Temperature Radiometer},
  year =	 2018,
  pages =	 {3015-3018},
  doi =		 {10.1109/IGARSS.2018.8517857}
}

@article{SKAKUN2022112990,
  title =	 {Cloud Mask Intercomparison eXercise (CMIX): An
                  evaluation of cloud masking algorithms for Landsat 8
                  and Sentinel-2},
  journal =	 {Remote Sensing of Environment},
  volume =	 274,
  pages =	 112990,
  year =	 2022,
  issn =	 {0034-4257},
  doi =		 {https://doi.org/10.1016/j.rse.2022.112990},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S0034425722001043},
  author =	 {Sergii Skakun and Jan Wevers and Carsten Brockmann
                  and Georgia Doxani and Matej Aleksandrov and Matej
                  Batič and David Frantz and Ferran Gascon and Luis
                  Gómez-Chova and Olivier Hagolle and Dan
                  López-Puigdollers and Jérôme Louis and Matic Lubej
                  and Gonzalo Mateo-García and Julien Osman and Devis
                  Peressutti and Bringfried Pflug and Jernej Puc and
                  Rudolf Richter and Jean-Claude Roger and Pat
                  Scaramuzza and Eric Vermote and Nejc Vesel and Anže
                  Zupanc and Lojze Žust},
  keywords =	 {Cloud, Intercomparison, Validation, Landsat 8,
                  Sentinel-2, CMIX, CEOS},
  abstract =	 {Cloud cover is a major limiting factor in exploiting
                  time-series data acquired by optical spaceborne
                  remote sensing sensors. Multiple methods have been
                  developed to address the problem of cloud detection
                  in satellite imagery and a number of cloud masking
                  algorithms have been developed for optical sensors
                  but very few studies have carried out quantitative
                  intercomparison of state-of-the-art methods in this
                  domain. This paper summarizes results of the first
                  Cloud Masking Intercomparison eXercise (CMIX)
                  conducted within the Committee Earth Observation
                  Satellites (CEOS) Working Group on Calibration &
                  Validation (WGCV). CEOS is the forum for space
                  agency coordination and cooperation on Earth
                  observations, with activities organized under
                  working groups. CMIX, as one such activity, is an
                  international collaborative effort aimed at
                  intercomparing cloud detection algorithms for
                  moderate-spatial resolution (10–30 m) spaceborne
                  optical sensors. The focus of CMIX is on open and
                  free imagery acquired by the Landsat 8 (NASA/USGS)
                  and Sentinel-2 (ESA) missions. Ten algorithms
                  developed by nine teams from fourteen different
                  organizations representing universities, research
                  centers and industry, as well as space agencies
                  (CNES, ESA, DLR, and NASA), are evaluated within the
                  CMIX. Those algorithms vary in their approach and
                  concepts utilized which were based on various
                  spectral properties, spatial and temporal features,
                  as well as machine learning methods. Algorithm
                  outputs are evaluated against existing reference
                  cloud mask datasets. Those datasets vary in sampling
                  methods, geographical distribution, sample unit
                  (points, polygons, full image labels), and
                  generation approaches (experts, machine learning,
                  sky images). Overall, the performance of algorithms
                  varied depending on the reference dataset, which can
                  be attributed to differences in how the reference
                  datasets were produced. The algorithms were in good
                  agreement for thick cloud detection, which were
                  opaque and had lower uncertainties in their
                  identification, in contrast to thin/semi-transparent
                  clouds detection. Not only did CMIX allow
                  identification of strengths and weaknesses of
                  existing algorithms and potential areas of
                  improvements, but also the problems associated with
                  the existing reference datasets. The paper concludes
                  with recommendations on generating new reference
                  datasets, metrics, and an analysis framework to be
                  further exploited and additional input datasets to
                  be considered by future CMIX activities.}
}

@article{FERNANDEZMORAN2021238,
  title =	 {Towards a novel approach for Sentinel-3 synergistic
                  OLCI/SLSTR cloud and cloud shadow detection based on
                  stereo cloud-top height estimation},
  journal =	 {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume =	 181,
  pages =	 {238-253},
  year =	 2021,
  issn =	 {0924-2716},
  doi =		 {https://doi.org/10.1016/j.isprsjprs.2021.09.013},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S0924271621002458},
  author =	 {Roberto Fernandez-Moran and Luis Gómez-Chova and
                  Luis Alonso and Gonzalo Mateo-García and Dan
                  López-Puigdollers},
  keywords =	 {Cloud mask, Cloud shadow, Cloud detection,
                  Sentinel-3, Cloud top height, OLCI, SLSTR},
  abstract =	 {Sentinel-3 is an Earth observation satellite
                  constellation launched by the European Space
                  Agency. Each satellite carries two optical
                  multispectral instruments: the Ocean and Land Colour
                  Instrument (OLCI) and the Sea and Land Surface
                  Temperature Radiometer (SLSTR). OLCI and SLSTR
                  sensors produce images covering the visible and
                  infrared spectrum that can be collocated in order to
                  generate synergistic products. In Earth observation,
                  a particular weakness of optical sensors is their
                  high sensitivity to clouds and their shadows. An
                  incorrect cloud and cloud shadow detection leads to
                  mistakes in both land and ocean retrievals of
                  biophysical parameters. In order to exploit both
                  OLCI and SLSTR capabilities, image co-registration
                  at ground level is needed. However, applying such
                  collocation of the images results in cloud location
                  mismatches due to the different viewing angles of
                  OLCI and SLSTR, which complicates the synergistic
                  cloud detection. This study seeks to provide a
                  solution to correctly obtain the projected clouds
                  based on the estimation of cloud top heights in
                  order to better collocate clouds between sensors and
                  detect their shadows. The study presents a forward
                  and backward method to estimate the real nadir
                  position of a cloud on the satellite image starting
                  from an existing cloud mask, as well as the
                  corresponding cloud projections on the surface
                  depending on the solar and sensor viewing
                  angles. The estimation of cloud top heights is based
                  on differences in the cloud projections from SLSTR
                  nadir and oblique views. Experimental results show
                  that the stereo cloud matching based on maximum
                  cross-correlation between SLSTR nadir and oblique
                  spectra was the most robust method to match SLSTR
                  clouds for both nadir and oblique views as compared
                  to spectral distance and spectral angle
                  minimization. We test the method over several images
                  around the world, leading to higher overall accuracy
                  (OA) as compared to Sentinel-3 official products,
                  both in detecting SLSTR clouds and OLCI cloud
                  shadows (SLSTR nadir OA = 93.6%, SLSTR oblique
                  OA = 88.7%, OLCI cloud shadow OA = 93.9% for the
                  stereo matcher, against 82.2%, 81.3% and 90.5%,
                  respectively, for the official Sentinel-3
                  products). This study also provides a starting point
                  in the development of a cloud screening approach for
                  the upcoming Fluorescence Explorer (FLEX) satellite
                  mission, expected to fly in tandem with Sentinel-3.}
}

@article{las-2023-mlcommons-edu-eq,
  author =	 {von Laszewski, Gregor and Fleischer, J.P. and
                  Knuuti, R. and Fox, G.C. and Kolessar, J. and
                  Butler, T.S. and Fox, J.},
  journal =	 {Frontiers in High Performance Computing,},
  month =	 {October},
  number =	 1233877,
  pages =	 31,
  title =	 {Opportunities for enhancing MLCommons efforts while
                  leveraging insights from educational MLCommons
                  earthquake benchmarks efforts},
  url =		 {https://doi.org/10.3389/fhpcp.2023.1233877},
  volume =	 1,
  year =	 2023
}

@misc{github-cloudmesh-ee,
  author={von Laszewski, Gregor},
  title =	 {{Cloudmesh Experiment Executor Repository}},
  year =	 2022,
  month =	 oct,
  note =	 {formerly know as cloudmesh-sbatch
                  \url{https://github.com/cloudmesh/cloudmesh-ee}},
  url =		 {https://github.com/cloudmesh/cloudmesh-ee}
}

% misc{github-cloudmesh-sbatch,
%	author = {von Laszewski, Gregor},
%	title = {{Hyperparameter Search Batch Job Generator}},
%	howpublished = {GitHub},
%	year = {2022},
%	month = oct,
%	note = {[Online; accessed 14. Oct. 2022]},
%	url = {https://github.com/cloudmesh/cloudmesh-sbatch}
% }

@misc{las-2023-ai-workflow,
  title =	 {Hybrid Reusable Computational Analytics Workflow
                  Management with Cloudmesh Applied to the MLCommons
                  Cloudmask Application},
  author =	 {von Laszewski, Gregor and J.P. Fleischer and
                  Geoffrey C. Fox and Juri Papay and Sam Jackson},
  year =	 2023,
  archivePrefix ={arXiv},
  primaryClass = {cs.DC},
  url =		 {https://arxiv.org/pdf/2210.16941.pdf}
}

@InProceedings{las-2023-escience-cloudmask,
  author={von Laszewski, Gregor and Fleischer, J.P. and Fox, Geoffrey C. and Papay, Juri and Jackson, Sam and Thiyagalingam, Jeyan},
  booktitle={2023 IEEE 19th International Conference on e-Science (e-Science)}, 
  title={Templated Hybrid Reusable Computational Analytics Workflow Management with Cloudmesh, Applied to the Deep Learning MLCommons Cloudmask Application}, 
  volume={},
  number={},
  year =	 2023,
  pages={1-6},
  month =	 oct,
  address =	 {Limassol, Cyprus},
  organization = {2nd Workshop on Reproducible Workflows, Data
                  Management, and Security},
  publisher =	 {IEEE},
  doi={10.1109/e-Science58273.2023.10254942}},
  url = {https://ieeexplore.ieee.org/document/10254942},
  note =	 {A longer paper draft is available at
                  \cite{las-2023-ai-workflow}}
}

@misc{www-fair,
  author ={{Go Fair}},
  title =	 {FAIR Principles},
  howpublished = {Web Page},
  url =		 {https://www.go-fair.org/fair-principles/},
  month =	 jul,
  year =	 2023
}

@misc{cloudmesh-stopwatch,
  author =	 {von Laszewski, Gregor},
  howpublished =	 {GitHub},
  month =	 may,
  note =	 {[Accessed April 13, 2023]},
  title =	 {{Cloudmesh Common StopWatch}},
  year =	 2022,
  url =
                  {https://github.com/cloudmesh/cloudmesh-common/blob/main/
                  cloudmesh/common/StopWatch.py},
}

@misc{www-mlcommons-research,
  title =	 {{MLCommons Research Working Group}},
  howpublished = {Web Page},
  author =	 {{MLCommons}},
  year =	 2023,
  month =	 jun,
  note =	 {[Online; accessed 23. Jun. 2023]},
  url =		 {https://mlcommons.org/en/groups/research}
}

@misc{www-mlcommons-science-github,
  author =	 {{MLCommons}},
  title =	 {{MLCommons Science Working Group}},
  howpublished = {GitHub},
  year =	 2023,
  month =	 jun,
  note =	 {[Online; accessed 23. Jun. 2023]},
  url =
                  {https://github.com/mlcommons/science/tree/main/benchmarks/cloudmask}
}

@inproceedings{Caruana2000OverfittingIN,
  author =	 {Caruana, Rich and Lawrence, Steve and Giles, C.},
  booktitle =	 {Advances in Neural Information Processing Systems},
  editor =	 {T. Leen and T. Dietterich and V. Tresp},
  publisher =	 {MIT Press},
  title =	 {Overfitting in Neural Nets: Backpropagation,
                  Conjugate Gradient, and Early Stopping},
  url =
                  {https://proceedings.neurips.cc/paper_files/paper/2000/file/059fdcd96baeb75112f09fa1dcc740cc-Paper.pdf},
  volume =	 13,
  year =	 2000,
  pages ={7},
  month = may,
  address = {Denver, CO, USA}
}

@article{Li2019DeepLB,
  title =	 {Deep learning based cloud detection for medium and
                  high resolution remote sensing images of different
                  sensors},
  journal =	 {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume =	 150,
  pages =	 {197-212},
  year =	 2019,
  issn =	 {0924-2716},
  doi =		 {https://doi.org/10.1016/j.isprsjprs.2019.02.017},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S0924271619300565},
  author =	 {Zhiwei Li and Huanfeng Shen and Qing Cheng and Yuhao
                  Liu and Shucheng You and Zongyi He},
  keywords =	 {Cloud detection, Cloud shadow, Convolutional neural
                  network, Multi-scale, Convolutional feature fusion,
                  MSCFF},
  abstract =	 {Cloud detection is an important preprocessing step
                  for the precise application of optical satellite
                  imagery. In this paper, we propose a deep learning
                  based cloud detection method named multi-scale
                  convolutional feature fusion (MSCFF) for remote
                  sensing images of different sensors. In the network
                  architecture of MSCFF, the symmetric encoder-decoder
                  module, which provides both local and global context
                  by densifying feature maps with trainable
                  convolutional filter banks, is utilized to extract
                  multi-scale and high-level spatial features. The
                  feature maps of multiple scales are then up-sampled
                  and concatenated, and a novel multi-scale feature
                  fusion module is designed to fuse the features of
                  different scales for the output. The two output
                  feature maps of the network are cloud and cloud
                  shadow maps, which are in turn fed to binary
                  classifiers outside the model to obtain the final
                  cloud and cloud shadow mask. The MSCFF method was
                  validated on hundreds of globally distributed
                  optical satellite images, with spatial resolutions
                  ranging from 0.5 to 50 m, including Landsat-5/7/8,
                  Gaofen-1/2/4, Sentinel-2, Ziyuan-3, CBERS-04,
                  Huanjing-1, and collected high-resolution images
                  exported from Google Earth. The experimental results
                  show that MSCFF achieves a higher accuracy than the
                  traditional rule-based cloud detection methods and
                  the state-of-the-art deep learning models,
                  especially in bright surface covered areas. The
                  effectiveness of MSCFF means that it has great
                  promise for the practical application of cloud
                  detection for multiple types of medium and
                  high-resolution remote sensing images. Our
                  established global high-resolution cloud detection
                  validation dataset has been made available online
                  (http://sendimage.whu.edu.cn/en/mscff/).}
}


@article{Domnich2021KappaMaskAC,
  AUTHOR =	 {Domnich, Marharyta and Sünter, Indrek and Trofimov,
                  Heido and Wold, Olga and Harun, Fariha and
                  Kostiukhin, Anton and Järveoja, Mihkel and Veske,
                  Mihkel and Tamm, Tanel and Voormansik, Kaupo and
                  Olesk, Aire and Boccia, Valentina and Longepe,
                  Nicolas and Cadau, Enrico Giuseppe},
  TITLE =	 {KappaMask: AI-Based Cloudmask Processor for
                  Sentinel-2},
  JOURNAL =	 {Remote Sensing},
  VOLUME =	 13,
  YEAR =	 2021,
  NUMBER =	 20,
  ARTICLE-NUMBER = 4100,
  pages =	 {1-22},
  URL =		 {https://www.mdpi.com/2072-4292/13/20/4100},
  ISSN =	 {2072-4292},
  ABSTRACT =	 {The Copernicus Sentinel-2 mission operated by the
                  European Space Agency (ESA) provides comprehensive
                  and continuous multi-spectral observations of all
                  the Earth’s land surface since mid-2015. Clouds and
                  cloud shadows significantly decrease the usability
                  of optical satellite data, especially in
                  agricultural applications; therefore, an accurate
                  and reliable cloud mask is mandatory for effective
                  EO optical data exploitation. During the last few
                  years, image segmentation techniques have developed
                  rapidly with the exploitation of neural network
                  capabilities. With this perspective, the KappaMask
                  processor using U-Net architecture was developed
                  with the ability to generate a classification mask
                  over northern latitudes into the following classes:
                  clear, cloud shadow, semi-transparent cloud (thin
                  clouds), cloud and invalid. For training, a
                  Sentinel-2 dataset covering the Northern European
                  terrestrial area was labelled. KappaMask provides a
                  10 m classification mask for Sentinel-2 Level-2A
                  (L2A) and Level-1C (L1C) products. The total dice
                  coefficient on the test dataset, which was not seen
                  by the model at any stage, was 80% for KappaMask L2A
                  and 76% for KappaMask L1C for clear, cloud shadow,
                  semi-transparent and cloud classes. A comparison
                  with rule-based cloud mask methods was then
                  performed on the same test dataset, where Sen2Cor
                  reached 59% dice coefficient for clear, cloud
                  shadow, semi-transparent and cloud classes, Fmask
                  reached 61% for clear, cloud shadow and cloud
                  classes and Maja reached 51% for clear and cloud
                  classes. The closest machine learning open-source
                  cloud classification mask, S2cloudless, had a 63%
                  dice coefficient providing only cloud and clear
                  classes, while KappaMask L2A, with a more complex
                  classification schema, outperformed S2cloudless by
                  17%.},
  DOI =		 {10.3390/rs13204100}
}






%TODO

@article{Zhu2012ObjectbasedCA,
  title =	 {Object-based cloud and cloud shadow detection in
                  Landsat imagery},
  journal =	 {Remote Sensing of Environment},
  volume =	 118,
  pages =	 {83-94},
  year =	 2012,
  issn =	 {0034-4257},
  doi =		 {https://doi.org/10.1016/j.rse.2011.10.028},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S0034425711003853},
  author =	 {Zhe Zhu and Curtis E. Woodcock},
  keywords =	 {Landsat, Cloud, Cloud shadow, Fmask, Object-based,
                  Detection},
  abstract =	 {A new method called Fmask (Function of mask) for
                  cloud and cloud shadow detection in Landsat imagery
                  is provided. Landsat Top of Atmosphere (TOA)
                  reflectance and Brightness Temperature (BT) are used
                  as inputs. Fmask first uses rules based on cloud
                  physical properties to separate Potential Cloud
                  Pixels (PCPs) and clear-sky pixels. Next, a
                  normalized temperature probability, spectral
                  variability probability, and brightness probability
                  are combined to produce a probability mask for
                  clouds over land and water separately. Then, the
                  PCPs and the cloud probability mask are used
                  together to derive the potential cloud layer. The
                  darkening effect of the cloud shadows in the Near
                  Infrared (NIR) Band is used to generate a potential
                  shadow layer by applying the flood-fill
                  transformation. Subsequently, 3D cloud objects are
                  determined via segmentation of the potential cloud
                  layer and assumption of a constant temperature lapse
                  rate within each cloud object. The view angle of the
                  satellite sensor and the illuminating angle are used
                  to predict possible cloud shadow locations and
                  select the one that has the maximum similarity with
                  the potential cloud shadow mask. If the scene has
                  snow, a snow mask is also produced. For a globally
                  distributed set of reference data, the average Fmask
                  overall cloud accuracy is as high as 96.4%. The goal
                  is development of a cloud and cloud shadow detection
                  algorithm suitable for routine usage with Landsat
                  images.}
}


%TODO

@inproceedings{Farrell2021MLPerfHA,
  author =	 {Steven Farrell and Murali Emani and Jacob Balma and
                  Lukas Drescher and Aleksandr Drozd and Andreas Fink
                  and Geoffrey C. Fox and David Kanter and Thorsten
                  Kurth and Peter Mattson and Dawei Mu and Amit Ruhela
                  and Kento Sato and Koichi Shirahata and Tsuguchika
                  Tabaru and Aristeidis Tsaris and Jan Balewski and
                  Ben Cumming and Takumi Danjo and Jens Domke and
                  Takaaki Fukai and Naoto Fukumoto and Tatsuya Fukushi
                  and Balazs Gerofi and Takumi Honda and Toshiyuki
                  Imamura and Akihiko Kasagi and Kentaro Kawakami and
                  Shuhei Kudo and Akiyoshi Kuroda and Maxime
                  Martinasso and Satoshi Matsuoka and Henrique
                  Mendon{\c{c}}a and Kazuki Minami and Prabhat Ram and
                  Takashi Sawada and Mallikarjun Shankar and Tom
                  St. John and Akihiro Tabuchi and Venkatram
                  Vishwanath and Mohamed Wahib and Masafumi Yamazaki
                  and Junqi Yin},
  title =	 {MLPerf{\texttrademark} {HPC:} {A} Holistic Benchmark
                  Suite for Scientific Machine Learning on {HPC}
                  Systems},
  booktitle =	 {{IEEE/ACM} Workshop on Machine Learning in High
                  Performance Computing Environments, MLHPC@SC 2021,
                  St. Louis, MO, USA, November 15, 2021},
  pages =	 {33--45},
  publisher =	 {{IEEE}},
  year =	 2021,
  url =		 {https://doi.org/10.1109/MLHPC54614.2021.00009},
  doi =		 {10.1109/MLHPC54614.2021.00009},
  address =	 {St. Louis, MO}
}

@article{Yan2018CloudAC,
  author =	 {Yan, Zhiyuan and Yan, Menglong and Sun, Hao and Fu,
                  Kun and Hong, Jun and Sun, Jun and Zhang, Yi and
                  Sun, Xian},
  journal =	 {IEEE Geoscience and Remote Sensing Letters},
  title =	 {Cloud and cloud shadow detection using multilevel
                  feature fused segmentation network},
  year =	 2018,
  volume =	 15,
  number =	 10,
  pages =	 {1600-1604},
  doi =		 {10.1109/LGRS.2018.2846802}
}

@article{Saunders1986AnAS,
  author =	 {Saunders, Roger W. },
  title =	 {An automated scheme for the removal of cloud
                  contamination from AVHRR radiances over western
                  Europe},
  journal =	 {International Journal of Remote Sensing},
  volume =	 7,
  number =	 7,
  pages =	 {867-886},
  year =	 1986,
  publisher =	 {Taylor & Francis},
  doi =		 {10.1080/01431168608948896},
  URL =		 { https://doi.org/10.1080/01431168608948896 },
  eprint =	 { https://doi.org/10.1080/01431168608948896 }
}

@article{Saunders1988AnIM,
  author =	 {Saunders, Roger W.  and Kriebel, Karl Theodor },
  title =	 {An improved method for detecting clear sky and
                  cloudy radiances from AVHRR data},
  journal =	 {International Journal of Remote Sensing},
  volume =	 9,
  number =	 1,
  pages =	 {123-150},
  year =	 1988,
  doi =		 {10.1080/01431168808954841},
  URL =		 {https://doi.org/10.1080/01431168808954841},
}


@misc{www-mlcommons-science,
author = {Fox, G. and Hey, T. and Thiyagalingam, J},
title = {Science data working group of MLCommons research. Web Page.},
url = {https://mlcommons.org/en/groups/research-science/},
month = apr,
year = 2023,
urldate = {04/20/2023}
}

@misc{Sentinel84:online,
  author =	 {{Sentinel-3}},
  title =	 {Mission Summary},
  howpublished = {Web Page},
  url =
                  {https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-3/overview/mission-summary},
  month =	 dec,
  year =	 2023
}

@misc{www-sentinel92,
author = {{Sentinel Copernicus Operation}},
title = {Sentinel-3 - Sentinel Online},
url = {https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-3},
month = apr,
year = 2023,
urldate = {04/20/2023}
}

@misc{www-lsf,
  author =	 {{IBM}},
  title =	 {Introduction to IBM Spectrum LSF},
  howpublished = {Web Page},
  url =
                  {https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=overview-lsf-introduction},
  month =	 apr,
  year =	 2023
}

@misc{www-slurm,
  author = {{SchedMD}},
  journal =	 {Web page},
  key =		 {SLURM},
  howpublished = {Web page},
  url =		 {https://slurm.schedmd.com},
  title =	 {Homepage},
  year =	 2003,
  month =	 apr
}

@misc{github-laszewsk-mlcommons,
  author =	 {von Laszewski, Gregor and {et.al.}},
  title =	 {laszewsk/mlcommons:
                  https://laszewsk.github.io/mlcommons/},
  url =		 {https://github.com/laszewsk/mlcommons},
  month =	 apr,
  year =	 2023,
  urldate =	 {04/20/2023}
}

@misc{www-greene,
author = {{New York University}},
title = {NYU Greene Supercomputer},
url = {https://www.nyu.edu/life/information-technology/research-computing-services/high-performance-computing/high-performance-computing-nyu-it/hpc-supercomputer-clusters/greene.html},
month = apr,
year = 2023 ,
urldate = {04/20/2023}
}

@misc{top500-greene,
  author =	 {{Top500}},
  title =	 {Greene - ThinkSystem SR650, Xeon Gold 6240 18C
                  2.6GHz, Infiniband HDR},
  howpublished = {Web Page},
  url =		 {https://www.top500.org/system/179851/},
  month =	 apr,
  year =	 2023
}

@InCollection{las22-cloudmesh-cc-reu,
  author =	 {von Laszewski, Gregor and Fleischer, J.P.},
  title =	 {{Hybrid Multi-Cloud Analytics Services Framework}},
  booktitle =	 {Computing for Global Challenges Symposium},
  publisher =	 {Online},
  year =	 2022,
  type =	 {Poster},
  edition =	 {Oct. 2022},
  month =	 jul,
  address =	 {University of Virginia, Charlottesville, VA},
  note =	 {corrected and updated Oct. 2022},
  url =
                  {https://raw.githubusercontent.com/cloudmesh/cloudmesh-cc/main/documents/analytics-service.pdf}
}

@misc{github-cloudmesh-cc,
  author =	 {von Laszewski, Gregor and J.P. Fleischer},
  title =	 {{Hybrid Multi-Cloud Analytics Services Framework}},
  howpublished = {GitHub},
  year =	 2022,
  month =	 oct,
  note =	 {[Online; accessed 14. Oct. 2022]},
  url =		 {https://github.com/cloudmesh/cloudmesh-cc}
}

@misc{github-mlcommons-logging,
  author =	 {MLCommons},
  title =	 {GitHub MLCommons Logging},
  year =	 2022,
  url =		 {https://github.com/mlcommons/logging},
}

@article{las-2021-covid,
  author =	 {Geoffrey C. Fox and von Laszewski, Gregor and Fugang
                  Wang and Saumyadipta Pyne},
  title =	 {AICov: An Integrative Deep Learning Framework for
                  COVID-19 Forecasting with Population Covariates},
  journal =	 {Journal of Data Science},
  volume =	 19,
  number =	 2,
  year =	 2021,
  pages =	 {293--313},
  doi =		 {10.6339/21-JDS1007},
  issn =	 {1680-743X},
  publisher =	 {School of Statistics, Renmin University of China}
}

@misc{google-meeting-notes,
  author =	 {Varshitha Chennamsetti and Alex Tang and Ruochen Gu
                  and von Laszewski, Gregor},
  title =	 {{NYU-MLCommons Meeting Notes}},
  howpublished = {Google Drive},
  year =	 2022,
  month =	 oct,
  note =	 {[Online; accessed 25. Mar. 2023]},
  url =
                  {https://docs.google.com/document/d/1LUuVSeLYv-717TJxtyikihLmuyf6at50FNBn57Doo_4/edit#heading=h.7p7jjuq4vbsm}
}

@inbook{Thiyagalingam2022AIBF,
  author =	 {Thiyagalingam, Jeyan and von Laszewski, Gregor and
                  Yin, Junqi and Emani, Murali and Papay, Juri and
                  Barrett, Gregg and Luszczek, Piotr and Tsaris,
                  Aristeidis and Kirkpatrick, Christine and Wang,
                  Feiyi and Gibbs, Tom and Vishwanath, Venkatram and
                  Shankar, Mallikarjun and Fox, Geoffrey and Hey,
                  Tony},
  year =	 2023,
  month =	 01,
  pages =	 {47-64},
  title =	 {AI Benchmarking for Science: Efforts from the
                  MLCommons Science Working Group},
  isbn =	 {978-3-031-23219-0},
  doi =		 {10.1007/978-3-031-23220-6_4},
  publisher =	 {Springer},
  booktitle =	 {High Performance Computing. ISC High Performance
                  2022 International Workshops},
  address =	 {Hamburg, Germany}
}

@article{Merchant2005ProbabilisticPB,
  title =	 {Probabilistic physically based cloud screening of
                  satellite infrared imagery for operational sea
                  surface temperature retrieval},
  author =	 {Christopher J. Merchant and Andrew R. Harris and
                  Eileen Maturi and S. Maccallum},
  journal =	 {Quarterly Journal of the Royal Meteorological
                  Society, Part A},
  year =	 2005,
  volume =	 131,
  month =	 oct,
  pages =	 {2735–2755},
  url =		 {https://doi.org/10.1256/qj.05.15}
}

@article{WIELAND2019111203,
  title =	 {Multi-sensor cloud and cloud shadow segmentation
                  with a convolutional neural network},
  journal =	 {Remote Sensing of Environment},
  volume =	 230,
  pages =	 111203,
  year =	 2019,
  issn =	 {0034-4257},
  doi =		 {https://doi.org/10.1016/j.rse.2019.05.022},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S0034425719302159},
  author =	 {Marc Wieland and Yu Li and Sandro Martinis},
  keywords =	 {Cloud, Cloud shadow, Convolutional neural network,
                  Landsat, Sentinel-2}
}

@article{Ronneberger2015UNetCN,
  title =	 {U-Net: Convolutional Networks for Biomedical Image
                  Segmentation},
  author =	 {Olaf Ronneberger and Philipp Fischer and Thomas
                  Brox},
  journal =	 {ArXiv},
  year =	 2015,
  volume =	 {abs/1505.04597},
  pages =	 {1-8},
  url ={https://arxiv.org/abs/1505.04597}
}

@InProceedings{RFB15a,
  author =	 {Ronneberger, Olaf and Fischer, Philipp and Brox,
                  Thomas},
  editor =	 {Navab, Nassir and Hornegger, Joachim and Wells,
                  William M.  and Frangi, Alejandro F.},
  title =	 {U-Net: Convolutional Networks for Biomedical Image
                  Segmentation},
  booktitle =	 {Medical Image Computing and Computer-Assisted
                  Intervention -- MICCAI 2015},
  year =	 2015,
  publisher =	 {Springer International Publishing},
  address =	 {Cham},
  pages =	 {234--241},
  abstract =	 {There is large consent that successful training of
                  deep networks requires many thousand annotated
                  training samples. In this paper, we present a
                  network and training strategy that relies on the
                  strong use of data augmentation to use the available
                  annotated samples more efficiently. The architecture
                  consists of a contracting path to capture context
                  and a symmetric expanding path that enables precise
                  localization. We show that such a network can be
                  trained end-to-end from very few images and
                  outperforms the prior best method (a sliding-window
                  convolutional network) on the ISBI challenge for
                  segmentation of neuronal structures in electron
                  microscopic stacks. Using the same network trained
                  on transmitted light microscopy images (phase
                  contrast and DIC) we won the ISBI cell tracking
                  challenge 2015 in these categories by a large
                  margin. Moreover, the network is fast. Segmentation
                  of a 512x512 image takes less than a second on a
                  recent GPU. The full implementation (based on Caffe)
                  and the trained networks are available at
                  http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
  isbn =	 {978-3-319-24574-4},
  url ={https://arxiv.org/abs/1505.04597}
}

@article{JEPPESEN2019247,
  title =	 {A cloud detection algorithm for satellite imagery
                  based on deep learning},
  journal =	 {Remote Sensing of Environment},
  volume =	 229,
  pages =	 {247-259},
  year =	 2019,
  issn =	 {0034-4257},
  doi =		 {https://doi.org/10.1016/j.rse.2019.03.039},
  url =
                  {https://www.sciencedirect.com/science/article/pii/S0034425719301294},
  author =	 {Jacob Høxbroe Jeppesen and Rune Hylsberg Jacobsen
                  and Fadil Inceoglu and Thomas Skjødeberg Toftegaard},
  keywords =	 {Cloud detection, Optical satellite imagery, Deep
                  learning, Open data}
}

@misc{las23-cloudmask,
  title =	 {MLCommons CloudMask Benchmark},
  author =	 {von Laszewski, Gregor and Varshitha Chennamsetti and
                  Laiba Mehnaz and Ruochen Gu and Sergey Samsonau and
                  Juri Papaya and Samuel Jackson and Geoffrey C. Fox },
  howpublished = {Draft Technical Report},
  month =	 may,
  year =	 2023,
  url =
                  {https://github.com/cyberaide/mlcommons-uva-cloudmask}
}

@misc{www-mlcommons-cloudmask-results,
  author =	 {{MLCommons}},
  title =	 {MLCommons cloudmask results Globus endpoint},
  howpublished = {globus.org},
  url =
                  {https://app.globus.org/file-manager?origin_id=285cade7-1a2f-4fa5-bc44-88475a1fc54a&origin_path=%2F},
  month =	 jun,
  year =	 2023
}
